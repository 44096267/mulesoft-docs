= Prerequisites for Installing the Anypoint Platform On-premises Edition
:keywords:anypoint platform, on premises


This section contains hardware, software and networking requirements for installing the link:/anypoint-platform-on-premises/v/1.5.0/index[Anypoint Platform on-Premises Edition].

If you comply with the necessary specs, see the link:/anypoint-platform-on-premises/v/1.5.0/installing-anypoint-on-premises[installation document]


== Hardware requirements

For production usage, it’s recommend to have at least 3 servers with the following minimum requirements each:

[%header%autowidth.spread]
|===
| Requirement |Value
|RAM |32GB
|CPU |8 Cores
|HDD 1 (OS + AnyPoint data) |500GB
|HDD 2 (for docker) |100GB
|HDD 3 (for etcd) |100GB
|Networking (connectivity between hosts)  |1GbE
|===

When using virtual machines, make sure that they are using different physical servers, otherwise HA won’t work properly.

== Software Requirements

=== Distributions

The following distributions are supported:

* RHEL >= 7.2.x
* CentOS >= 7.2.x

=== Packages to install


*Yum* is an open-source command-line package-management utility for Linux operating systems using the RPM Package Manager.

Through Yum, install the tool LVM. LVM (orLogical Volume Manager) is a tool that adds a layer of abstraction between your operating system and the disks/partitions it uses. You can install LVM through the following command:

----
`sudo yum install lvm2`
----

[NOTE]
You must use a user with root access to perform this installation.

=== Packages to uninstall

==== Docker

Docker should be uninstalled from the servers running the Anypoint Platform On-premises Edition. The Anypoint Platform installation includes its own packaging of Docker, officially supported by Kubernetes.

==== Local name service

Local caching DNS servers listening on port 53 should be removed, e.g. named, dnsmasq, bind or others.


==== Server settings

Make sure that server running installer and servers in the cluster are set to UTC timezone:

----
sudo unlink /etc/localtime
sudo ln -s /usr/share/zoneinfo/Etc/GMT /etc/localtime
----

== Networking Requirements

=== Static IPs

All servers in the cluster should have static private IPv4 assigned to them, these must persist between server restarts. If IPs don’t persist between reboots, the cluster will enter a failed state.

=== VXLAN

This version of Kubernetes sets up overlay VXLAN and uses UDP transport to encapsulate traffic.

There’s direct communication between components of the cluster via TCP. The table below shows the ports used for inter-host communication:

[%header%autowidth.spread]
|===
|Protocol |Port/Range |Purpose
|TCP | 6060 | Health check
|TCP |7469 |Cluster control plane
|UDP |8472 |Overlay VXLAN network
|TCP |6443 |Kubernetes API server
|TCP |8080 |Kubernetes API server
|TCP |10248-10255 |Kubernetes Kubelet
|TCP |2379, 2380, 4001, 7001 |etcd distributed database
|TCP | 5000 | Docker registry
|TCP |3008-3010, 3023-3025, 3080, 7575|cluster control plane
|TCP |30000-32767 |Internal services port range
|TCP | 7000, 7011, 7199, 9042, 9160 | Cassandra
|TCP | 18080, 18443 | Object store cluster
|TCP | 5431-5435 | Database cluster
|TCP |61008-61010 | Installer port ranges (only used during install)
|TCP |61022-61024 | Installer port ranges (only used during install)
|===

=== NAT Traffic

Kubernetes overlay network uses NAT in some cases. This requires that servers should be able to send and receive packages with a source and destination that is different from server’s internal IP.

=== SSL Certificate

In order to use the Anypoint Platform, you must provide SSL credentials. You can upload a certificate through the Anypoint Platform UI, see link:/access-management/on-premises-features#security[on-prem features]. This certificate must be trusted by every machine that’s connected to the platform.

[NOTE]
Keep in mind that you must register the same SSL certificate on every server with Mule Runtimes that are managed by this platform.

=== SMTP Server

Your network must include an SMTP server to manage e-mail alerts that are triggered by the platform. See link:/access-management/on-premises-features#smtp[on-prem features].

== Device Requirements

For the platform’s configuration you must assign two dedicated devices for use. One as a system state directory and the other as target for Docker devicemapper configuration. These two directories must exist on every node of your cluster.

[TIP]
====
You can create both these directories through the following command:
----
sudo mkfs.ext4 /dev/xvdb; sudo mkdir -p /var/lib/data; echo -e "[Mount]\nWhat=/dev/xvdb\nWhere=/var/lib/data\nType=ext4\n[Install]\nWantedBy=local-fs.target" |sudo tee /etc/systemd/system/var-lib-data.mount; sudo systemctl start var-lib-data.mount
----
====

=== Anypoint state directory
This is the directory where persistent Anypoint Platform data is stored.

Unless specified, the system directory (`/var/lib/data` by default) is created on whatever device /var/lib is mounted on. This directory will be automatically formatted and prepared for use.

[TIP]
This directory can be changed by providing an unformatted device (i.e. /dev/sdb) during installation for use as a state directory.

[NOTE]
It’s recommended to have at least 100Gb sized device for the Anypoint state directory.



=== Docker devicemapper

This device provides to Docker’s devicemapper.

Unless specified, Docker configuration defaults to the use of devicemapper in loopback mode (using /dev/loopX devices) which is not recommended for production. To configure Docker to use a dedicated device for devicemapper storage driver, an unformatted device (or a partition) (i.e. /dev/sdc) can be provided during installation. This directory will be automatically configured and set up for use.

Unformatted devices potentially usable for system directory / devicemapper are automatically discovered by agents running on each node. Discovered devices are offered on a drop-down menu for configuration before the installation is started.

[NOTE]
It’s recommended to have at least 100Gb sized device for the devicemapper directory.


=== Disk for Etcd

In production mode, it's highly recommend that you reserve a separate disk for Etcd due to performance and reliability reasons.

Mount the disk into /var/lib/gravity/planet/etcd
And the installer will pick up config automatically
