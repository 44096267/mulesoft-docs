= Streaming Data Processing with DataMapper

Especially useful when working with large datasets, Anypoint DataMapper supports streaming data input and output. For example, when reading information from a very large input file, you can use streaming you avoid having DataMapper load the whole file into memory. Instead, DataMapper works as a pipeline: it sequentially reads the file and store the data in a cache, performs data mapping, sends the output to the next transformer, empties the cache, then begins again. Using this procedure, DataMapper can parse a 500 MB CSV file using only about 75 MB of RAM, resulting in significant improvements in performance and resources utilization.

* Anypoint DataMapper streaming supports CSV and fixed width input and output formats.
* You can configure the size of the stream cache to optimize for performance.

== Assumptions

This document assumes the reader is familiar with the Anypoint DataMapper Transformer. If you are not, start from the beginning:  link:/docs/display/34X/Datamapper+User+Guide+and+Reference[DataMapper User Guide and Reference]. For a listing of all available tools in DataMapper, consult link:/docs/display/34X/DataMapper+Visual+Reference[DataMapper Visual Reference].

////

collapsed content

 View DataMapper Documentation Table of Contents

* link:/docs/display/34X/DataMapper+Concepts[DataMapper Concepts]
* link:/docs/display/34X/DataMapper+Visual+Reference[DataMapper Visual Reference]
* link:/docs/display/34X/Defining+DataMapper+Input+and+Output+Metadata[Defining DataMapper Input and Output Metadata]
** link:/docs/display/34X/Defining+Metadata+Using+Edit+Fields[Defining Metadata Using Edit Fields]
** link:/docs/display/34X/POJO+Class+Bindings+and+Factory+Classes[POJO Class Bindings and Factory Classes]
* link:/docs/display/34X/Building+a+Mapping+Flow+in+the+Graphical+Mapping+Editor[Building a Mapping Flow in the Graphical Mapping Editor]
** link:/docs/display/34X/Mapping+Flow+Input+and+Output+Properties[Mapping Flow Input and Output Properties]
** link:/docs/display/34X/DataMapper+Input+Error+Policy+for+Bad+Input+Data[DataMapper Input Error Policy for Bad Input Data]
** link:/docs/display/34X/Using+DataMapper+Lookup+Tables[Using DataMapper Lookup Tables]
** link:/docs/display/34X/Streaming+Data+Processing+with+DataMapper[Streaming Data Processing with DataMapper]
* link:/docs/display/34X/Updating+Metadata+in+an+Existing+Mapping[Updating Metadata in an Existing Mapping]
* link:/docs/display/34X/Mapping+Elements+Inside+Lists[Mapping Elements Inside Lists]
* link:/docs/display/34X/Previewing+DataMapper+Results+on+Sample+Data[Previewing DataMapper Results on Sample Data]
* link:/docs/display/34X/DataMapper+Examples[DataMapper Examples]
* link:/docs/display/34X/DataMapper+Supplemental+Topics[DataMapper Supplemental Topics]
** link:/docs/display/34X/Choosing+MEL+or+CTL2+as+Scripting+Engine[Choosing MEL or CTL2 as Scripting Engine]
** link:/docs/display/34X/DataMapper+Fixed+Width+Input+Format[DataMapper Fixed Width Input Format]
** link:/docs/display/34X/DataMapper+Flat-to-Structured+and+Structured-to-Flat+Mapping[DataMapper Flat-to-Structured and Structured-to-Flat Mapping]
////

== Setting Streaming in DataMapper

. To set the *Streaming* parameter in your data mapping flow, click the *Properties* icon at the top-right of the DataMapper view, to open the *Pattern Properties* window. 
+
image:/docs/download/attachments/95393442/properties.png?version=1&modificationDate=1374598587288[image]

. Click *Streaming*.
. In the *Pipe Size* input field, enter the desired size of the cache. The default is 2048.
* When working with files, the value of *Pipe Size* is expressed in bytes. 
* When working with collections, the value is expressed in number of collection elements.
+
image:/docs/download/attachments/95393442/streaming.png?version=1&modificationDate=1374598587504[image]

=== Handling Exceptions

If an exception occurs in the mapping, DataMapper stops the streaming engine as soon as possible. To avoid undesired consequences in case of failure (such as inserting only part of a row into a database) use link:/docs/display/34X/Transactions+Configuration+Reference[Transactions].

== Example

This example illustrates the use of the Streaming feature in Anypoint DataMapper.

An link:/docs/display/34X/HTTP+Endpoint+Reference[HTTP Endpoint] receives a CSV file, then passes it to DataMapper. DataMapper maps the input data from CSV to POJO. A link:/docs/display/34X/Database+%28JDBC%29+Endpoint+Reference[Database (JDBC) Endpoint] inserts the data into an external database.  In this scenario, DataMapper and the Database endpoint work in parallel as a pipeline, further improving application performance.

image:/docs/download/attachments/95393442/flow2.png?version=1&modificationDate=1374598586855[image]

The image below displays the DataMapper view as configured for this example.

image:/docs/download/attachments/95393442/dmview2.png?version=1&modificationDate=1374598587072[image]

Finally, the JDBC output endpoint receives the list of maps, then incorporates each item as a value in the SQL query for the external database.

[source]
----
INSERT INTO Persons (name, city, email, phone) VALUES (#[payload.name], #[payload.city], #[payload.email], #[payload.phone])
----
